{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","***What is olist?***\n","\n","Olist is an e-commerce enterprise based in Sao Paulo, Brazil, serving as an intermediary between numerous small businesses and customers seeking to purchase their products. The company had published a [dataset on Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) featuring data on 100,000 orders placed on various marketplaces from 2016 to 2018. The data includes information about the customers, the sellers, the products, and the order history. This dataset is useful for various data analysis tasks, including market research, customer segmentation, and sales forecasting. \n","\n","Consumers are influenced by product reviews when shopping online, and Olist could utilize this information to remove items with consistently negative reviews and promote those that are popular among customers.\n","\n","***The marketing funnel dataset***\n","\n","A seller join Olist through a marketing and sales funnel that was made public at this dataset. Description of steps:\n","\n","1. Sign-up at a landing page.\n","2. Get contacted by a Sales development Representative (SDR), confirm some information and schedule a consultancy.\n","3. Consultancy is made by a Sales Representative (SR). The SR may close the deal (lead sign up) or lose the deal (led leaves without sign up)\n","4. Lead becomes a seller and starts building his catalog on Olist.\n","5. His products are published on marketplaces and ready to sell!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<mark>The objective of this analyis will be to do the following:</mark>\n","- Finding out which sales funnel works best\n","- Finding The Customer LTV\n","- Monthly performance\n","- Best selling categories\n","- Future sales predictions\n","\n","We will also try to do these tasks in seperate analysis:\n","\n","*Customer behavior:* The dataset can be used to analyze customer behavior, such as buying patterns, preferences, and satisfaction levels.\n","\n","*Product analysis:* The dataset can help identify the best-selling products, the most profitable product categories, and the product categories with the highest returns.\n","\n","*Seller performance:* The dataset can be used to evaluate the performance of sellers based on factors such as delivery time, seller ratings, and order cancellations.\n","\n","*Geographical analysis:* The dataset can help identify the regions with the highest demand for products and the areas with the highest concentration of sellers.\n","\n","*Order processing:* The dataset can be used to analyze the order processing times, shipping delays, and customer feedback.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*We will start with importing the libraries and the datasets. Then we will join various datasets, do a basic EDA to see any patterns, conduct a RFM analyis and finally build a model using Tensorflow. That's the plan, lets see how it goes!* "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Importing Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import datetime as dt\n","\n","import seaborn as sns\n","sns.set_style('whitegrid', {'grid.linestyle': '--'})\n","\n","import time, warnings\n","import datetime as dt\n","\n","#visualizations\n","import matplotlib.pyplot as plt\n","from pandas.plotting import scatter_matrix\n","%matplotlib inline\n","import seaborn as sns\n","\n","from sklearn.preprocessing import MinMaxScaler\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Reading the various datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mql_id</th>\n","      <th>first_contact_date</th>\n","      <th>landing_page_id</th>\n","      <th>origin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>dac32acd4db4c29c230538b72f8dd87d</td>\n","      <td>2018-02-01</td>\n","      <td>88740e65d5d6b056e0cda098e1ea6313</td>\n","      <td>social</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8c18d1de7f67e60dbd64e3c07d7e9d5d</td>\n","      <td>2017-10-20</td>\n","      <td>007f9098284a86ee80ddeb25d53e0af8</td>\n","      <td>paid_search</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             mql_id first_contact_date   \n","0  dac32acd4db4c29c230538b72f8dd87d         2018-02-01  \\\n","1  8c18d1de7f67e60dbd64e3c07d7e9d5d         2017-10-20   \n","\n","                    landing_page_id       origin  \n","0  88740e65d5d6b056e0cda098e1ea6313       social  \n","1  007f9098284a86ee80ddeb25d53e0af8  paid_search  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# leads dataset\n","mql = pd.read_csv('marketing_qualified_leads.csv')\n","mql.head(2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["There are 8,000 rows out of which **495 have unique landing page id**"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8000 entries, 0 to 7999\n","Data columns (total 4 columns):\n"," #   Column              Non-Null Count  Dtype \n","---  ------              --------------  ----- \n"," 0   mql_id              8000 non-null   object\n"," 1   first_contact_date  8000 non-null   object\n"," 2   landing_page_id     8000 non-null   object\n"," 3   origin              7940 non-null   object\n","dtypes: object(4)\n","memory usage: 250.1+ KB\n"]}],"source":["mql.info()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["495"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["mql['landing_page_id'].nunique()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["These are the top 5 instances of landing page ids."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["landing_page_id\n","b76ef37428e6799c421989521c0e5077    912\n","22c29808c4f815213303f8933030604c    883\n","58326e62183c14b0c03085c33b9fdc44    495\n","88740e65d5d6b056e0cda098e1ea6313    445\n","ce1a65abd0973638f1c887a6efcfa82d    394\n","Name: count, dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["mql['landing_page_id'].value_counts().sort_values(ascending=False).head(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In terms of origin, we can see the following: "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["origin\n","organic_search    2296\n","paid_search       1586\n","social            1350\n","unknown           1099\n","direct_traffic     499\n","Name: count, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["mql['origin'].value_counts().sort_values(ascending=False).head(5)"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mql_id</th>\n","      <th>seller_id</th>\n","      <th>sdr_id</th>\n","      <th>sr_id</th>\n","      <th>won_date</th>\n","      <th>business_segment</th>\n","      <th>lead_type</th>\n","      <th>lead_behaviour_profile</th>\n","      <th>has_company</th>\n","      <th>has_gtin</th>\n","      <th>average_stock</th>\n","      <th>business_type</th>\n","      <th>declared_product_catalog_size</th>\n","      <th>declared_monthly_revenue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5420aad7fec3549a85876ba1c529bd84</td>\n","      <td>2c43fb513632d29b3b58df74816f1b06</td>\n","      <td>a8387c01a09e99ce014107505b92388c</td>\n","      <td>4ef15afb4b2723d8f3d81e51ec7afefe</td>\n","      <td>2018-02-26 19:58:54</td>\n","      <td>pet</td>\n","      <td>online_medium</td>\n","      <td>cat</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>reseller</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a555fb36b9368110ede0f043dfc3b9a0</td>\n","      <td>bbb7d7893a450660432ea6652310ebb7</td>\n","      <td>09285259593c61296eef10c734121d5b</td>\n","      <td>d3d1e91a157ea7f90548eef82f1955e3</td>\n","      <td>2018-05-08 20:17:59</td>\n","      <td>car_accessories</td>\n","      <td>industry</td>\n","      <td>eagle</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>reseller</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             mql_id                         seller_id   \n","0  5420aad7fec3549a85876ba1c529bd84  2c43fb513632d29b3b58df74816f1b06  \\\n","1  a555fb36b9368110ede0f043dfc3b9a0  bbb7d7893a450660432ea6652310ebb7   \n","\n","                             sdr_id                             sr_id   \n","0  a8387c01a09e99ce014107505b92388c  4ef15afb4b2723d8f3d81e51ec7afefe  \\\n","1  09285259593c61296eef10c734121d5b  d3d1e91a157ea7f90548eef82f1955e3   \n","\n","              won_date business_segment      lead_type lead_behaviour_profile   \n","0  2018-02-26 19:58:54              pet  online_medium                    cat  \\\n","1  2018-05-08 20:17:59  car_accessories       industry                  eagle   \n","\n","  has_company has_gtin average_stock business_type   \n","0         NaN      NaN           NaN      reseller  \\\n","1         NaN      NaN           NaN      reseller   \n","\n","   declared_product_catalog_size  declared_monthly_revenue  \n","0                            NaN                       0.0  \n","1                            NaN                       0.0  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# closed deals dataset\n","closed_deals = pd.read_csv('closed_deals.csv')\n","closed_deals.head(2)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["842"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["closed_deals['seller_id'].nunique()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["*Joining the marketing funnel dataset with the closed deals dataset, NaNs are leads that did not close a deal, which we will change to **No deals** on the seller_id column to ensure proper readability.*"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mql_id</th>\n","      <th>first_contact_date</th>\n","      <th>landing_page_id</th>\n","      <th>origin</th>\n","      <th>seller_id</th>\n","      <th>sdr_id</th>\n","      <th>sr_id</th>\n","      <th>won_date</th>\n","      <th>business_segment</th>\n","      <th>lead_type</th>\n","      <th>lead_behaviour_profile</th>\n","      <th>has_company</th>\n","      <th>has_gtin</th>\n","      <th>average_stock</th>\n","      <th>business_type</th>\n","      <th>declared_product_catalog_size</th>\n","      <th>declared_monthly_revenue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>dac32acd4db4c29c230538b72f8dd87d</td>\n","      <td>2018-02-01</td>\n","      <td>88740e65d5d6b056e0cda098e1ea6313</td>\n","      <td>social</td>\n","      <td>No deals</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8c18d1de7f67e60dbd64e3c07d7e9d5d</td>\n","      <td>2017-10-20</td>\n","      <td>007f9098284a86ee80ddeb25d53e0af8</td>\n","      <td>paid_search</td>\n","      <td>No deals</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b4bc852d233dfefc5131f593b538befa</td>\n","      <td>2018-03-22</td>\n","      <td>a7982125ff7aa3b2054c6e44f9d28522</td>\n","      <td>organic_search</td>\n","      <td>No deals</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6be030b81c75970747525b843c1ef4f8</td>\n","      <td>2018-01-22</td>\n","      <td>d45d558f0daeecf3cccdffe3c59684aa</td>\n","      <td>email</td>\n","      <td>No deals</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5420aad7fec3549a85876ba1c529bd84</td>\n","      <td>2018-02-21</td>\n","      <td>b48ec5f3b04e9068441002a19df93c6c</td>\n","      <td>organic_search</td>\n","      <td>2c43fb513632d29b3b58df74816f1b06</td>\n","      <td>a8387c01a09e99ce014107505b92388c</td>\n","      <td>4ef15afb4b2723d8f3d81e51ec7afefe</td>\n","      <td>2018-02-26 19:58:54</td>\n","      <td>pet</td>\n","      <td>online_medium</td>\n","      <td>cat</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>reseller</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             mql_id first_contact_date   \n","0  dac32acd4db4c29c230538b72f8dd87d         2018-02-01  \\\n","1  8c18d1de7f67e60dbd64e3c07d7e9d5d         2017-10-20   \n","2  b4bc852d233dfefc5131f593b538befa         2018-03-22   \n","3  6be030b81c75970747525b843c1ef4f8         2018-01-22   \n","4  5420aad7fec3549a85876ba1c529bd84         2018-02-21   \n","\n","                    landing_page_id          origin   \n","0  88740e65d5d6b056e0cda098e1ea6313          social  \\\n","1  007f9098284a86ee80ddeb25d53e0af8     paid_search   \n","2  a7982125ff7aa3b2054c6e44f9d28522  organic_search   \n","3  d45d558f0daeecf3cccdffe3c59684aa           email   \n","4  b48ec5f3b04e9068441002a19df93c6c  organic_search   \n","\n","                          seller_id                            sdr_id   \n","0                          No deals                               NaN  \\\n","1                          No deals                               NaN   \n","2                          No deals                               NaN   \n","3                          No deals                               NaN   \n","4  2c43fb513632d29b3b58df74816f1b06  a8387c01a09e99ce014107505b92388c   \n","\n","                              sr_id             won_date business_segment   \n","0                               NaN                  NaN              NaN  \\\n","1                               NaN                  NaN              NaN   \n","2                               NaN                  NaN              NaN   \n","3                               NaN                  NaN              NaN   \n","4  4ef15afb4b2723d8f3d81e51ec7afefe  2018-02-26 19:58:54              pet   \n","\n","       lead_type lead_behaviour_profile has_company has_gtin average_stock   \n","0            NaN                    NaN         NaN      NaN           NaN  \\\n","1            NaN                    NaN         NaN      NaN           NaN   \n","2            NaN                    NaN         NaN      NaN           NaN   \n","3            NaN                    NaN         NaN      NaN           NaN   \n","4  online_medium                    cat         NaN      NaN           NaN   \n","\n","  business_type  declared_product_catalog_size  declared_monthly_revenue  \n","0           NaN                            NaN                       NaN  \n","1           NaN                            NaN                       NaN  \n","2           NaN                            NaN                       NaN  \n","3           NaN                            NaN                       NaN  \n","4      reseller                            NaN                       0.0  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# marketing funnel dataset (NaNs are leads that did not close a deal)\n","mf = mql.merge(closed_deals, on='mql_id', how='left')\n","mf['seller_id'] = mf['seller_id'].fillna('No deals')\n","mf.head(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8000 entries, 0 to 7999\n","Data columns (total 17 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   mql_id                         8000 non-null   object \n"," 1   first_contact_date             8000 non-null   object \n"," 2   landing_page_id                8000 non-null   object \n"," 3   origin                         7940 non-null   object \n"," 4   seller_id                      8000 non-null   object \n"," 5   sdr_id                         842 non-null    object \n"," 6   sr_id                          842 non-null    object \n"," 7   won_date                       842 non-null    object \n"," 8   business_segment               841 non-null    object \n"," 9   lead_type                      836 non-null    object \n"," 10  lead_behaviour_profile         665 non-null    object \n"," 11  has_company                    63 non-null     object \n"," 12  has_gtin                       64 non-null     object \n"," 13  average_stock                  66 non-null     object \n"," 14  business_type                  832 non-null    object \n"," 15  declared_product_catalog_size  69 non-null     float64\n"," 16  declared_monthly_revenue       842 non-null    float64\n","dtypes: float64(2), object(15)\n","memory usage: 1.0+ MB\n"]}],"source":["mf.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We will join this dataset with the seller dataset to get more information and the sellers. <br>\n","We will do a basic EDA and try to answer the following: Which SR or SDR should talk with each kind of lead? Which deals should get closed?\n"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8000 entries, 0 to 7999\n","Data columns (total 20 columns):\n"," #   Column                         Non-Null Count  Dtype  \n","---  ------                         --------------  -----  \n"," 0   mql_id                         8000 non-null   object \n"," 1   first_contact_date             8000 non-null   object \n"," 2   landing_page_id                8000 non-null   object \n"," 3   origin                         7940 non-null   object \n"," 4   seller_id                      8000 non-null   object \n"," 5   sdr_id                         842 non-null    object \n"," 6   sr_id                          842 non-null    object \n"," 7   won_date                       842 non-null    object \n"," 8   business_segment               841 non-null    object \n"," 9   lead_type                      836 non-null    object \n"," 10  lead_behaviour_profile         665 non-null    object \n"," 11  has_company                    63 non-null     object \n"," 12  has_gtin                       64 non-null     object \n"," 13  average_stock                  66 non-null     object \n"," 14  business_type                  832 non-null    object \n"," 15  declared_product_catalog_size  69 non-null     float64\n"," 16  declared_monthly_revenue       842 non-null    float64\n"," 17  seller_zip_code_prefix         380 non-null    float64\n"," 18  seller_city                    380 non-null    object \n"," 19  seller_state                   380 non-null    object \n","dtypes: float64(3), object(17)\n","memory usage: 1.2+ MB\n"]}],"source":["# sellers dataset\n","sellers = pd.read_csv('sellers.csv')\n","# marketing funnel merged with sellers (this way we get the seller location and other relevant information)\n","mf_sellers = mf.merge(sellers, on='seller_id', how='left')\n","mf_sellers.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We will convert the dates to datetime objects and take the *difference between won_date and first_contact_date*, this will be a feature we will use in the model training."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert dates to datetime objects\n","mf_sellers[\"first_contact_date\"] = pd.to_datetime(mf_sellers[\"first_contact_date\"])\n","mf_sellers[\"won_date\"] = pd.to_datetime(mf_sellers[\"won_date\"])\n","mf_sellers[\"days_to_convert\"]=(mf_sellers[\"won_date\"]-mf_sellers[\"first_contact_date\"]).dt.days.fillna(\"No Deals\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mf_sellers.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# order items dataset\n","items = pd.read_csv('order_items.csv')\n","items.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# marketing funnel merged with items (this way you get products sold by sellers)\n","mf_items = mf.merge(items, on='seller_id', how='left')\n","mf_items.head(10)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Customer LTV"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Lifetime Value (LTV): Total Gross Revenue - Total Cost**\n","\n","As the dataset doesn't contain the **CAC(Customer Acquisition Costs)**- the lifetime value of each customer is the total revenue generated. Interestingly, the total revenue classification in an e-commerce can vary in the sense that if the platform is **\"sharing the shipping fees revenue with the seller\"** or not. Since nothing is indicated in the dataset, let us assume they are not. "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Getting the customer Data and orders data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_customer=pd.read_csv('customers.csv')\n","df_orders=pd.read_csv('orders.csv')\n","df_payments=pd.read_csv('order_payments.csv')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Customer Segmentation with RFM analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## getting order id by customer purchases \n","\n","df_customer_order=pd.merge(df_customer,df_orders[['order_id','customer_id','order_purchase_timestamp']],on='customer_id')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## payments in same order id are combined to get total spending on an order\n","paid= df_payments[['order_id','payment_value']].groupby('order_id').sum().reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["paid"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# now the total payment by each order is merged to the cutomer who has bought it to find the total amount purchase\n","df_customer_order_rev=pd.merge(df_customer_order,paid,on='order_id')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# unwanted columns are dropped\n","df_customer_order_rev.drop(['customer_zip_code_prefix','customer_city','customer_state'],axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_customer_order_rev['order_purchase_timestamp']=pd.to_datetime(df_customer_order_rev['order_purchase_timestamp']).dt.date"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# find the last date on which customer made the purchase\n","recency=pd.DataFrame(df_customer_order_rev.groupby('customer_unique_id')['order_purchase_timestamp'].max())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# we take the maximum date of purchase made by customers as the date to calculate the recency of the purchase\n","## 2018-10-17\n","recency['recent_days']=recency['order_purchase_timestamp'].max()-recency['order_purchase_timestamp']\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["recency"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# int(recency['recent_days'][0].total_seconds()/86400)\n","recency['recent_days'] = recency['recent_days'].apply(lambda x:int(x.total_seconds()/86400))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# the number of times a unique customer has made purchase\n","frequency=pd.DataFrame(df_customer_order_rev.groupby('customer_unique_id')['customer_id'].count())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["monetary=pd.DataFrame(df_customer_order_rev[['customer_unique_id','payment_value']].groupby('customer_unique_id')['payment_value'].sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_rfm=pd.merge(recency,frequency,on='customer_unique_id')\n","df_rfm=pd.merge(df_rfm,monetary,on='customer_unique_id')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Freqency - Number of purchase made\n","## Recency- Days from last purchase\n","## Monetary-- total amount purchase for by a customer\n","df_rfm.drop(['order_purchase_timestamp'],axis=1,inplace=True)\n","df_rfm.reset_index(inplace=True)\n","df_rfm.columns=['Cust_unique_Id','Recency','Frequency','Monetary']\n","#use CustomerID as index\n","df_rfm.set_index('Cust_unique_Id',inplace=True)\n","df_rfm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## the descriptive stats for the RFM analysis\n","df_rfm.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Only **3.11% of the users have more than 1 purchase**, in this case, focusing on monetary value should be more critical for future marketing spends or it would be wise to spend on categories that drive repeat purchases. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["(df_rfm[df_rfm['Frequency']>1].shape[0]/96095)*100"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot RFM distributions\n","plt.figure(figsize=(12,10))\n","# Plot distribution of R\n","plt.subplot(3, 1, 1); sns.histplot(df_rfm['Recency'],kde=False)\n","# Plot distribution of F\n","plt.subplot(3, 1, 2); sns.histplot(df_rfm['Frequency'],kde=False)\n","# Plot distribution of M\n","plt.subplot(3, 1, 3); sns.histplot(df_rfm['Monetary'],kde=False)\n","# Show the plot\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**2. Sales Performance Overview**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In this part I will answer to following questions:\n","- What has performance been monthly?\n","- What are the best selling categories?\n","For this reason I will calcualte total revenue from closed deals and find out the top revenue-generating segment.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load datasets\n","order_items = pd.read_csv('../input/brazilian-ecommerce/olist_order_items_dataset.csv')\n","orders = pd.read_csv('../input/brazilian-ecommerce/olist_orders_dataset.csv',\n","                     parse_dates=['order_purchase_timestamp'])\n","products = pd.read_csv('../input/brazilian-ecommerce/olist_products_dataset.csv')\n","product_translation = pd.read_csv('../input/brazilian-ecommerce/product_category_name_translation.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["closed_deals.tail(100)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#get some info about dataframes\n","\n","print(closed_deals.shape)\n","print(order_items.shape)\n","print(orders.shape)\n","print(products.shape)\n","print(product_translation.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Merge all dataframes\n","df = pd.merge(closed_deals,order_items,\n","                how='inner', on='seller_id')\n","df = pd.merge(df, orders,\n","                how='inner', on='order_id')\n","df = pd.merge(df, products,\n","                how='inner', on='product_id')\n","df = pd.merge(df, product_translation,\n","                how='left', on='product_category_name')\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Sort out orders not devliered to customers\n","data = data[data['order_status'] == 'delivered']\n","\n","# Add a 'year-month' column\n","data['order_purchase_timestamp(y-m)'] = data['order_purchase_timestamp'].dt.to_period('M')\n","\n","print(data.shape)\n","data.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Monthly Revenues by Business Segment\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["columns = df.groupby(by='business_segment') \\\n","           .price \\\n","           .sum() \\\n","           .sort_values(ascending=False) \\\n","           .index\n","\n","monthly_revenue = df.groupby(['order_purchase_timestamp(y-m)', 'business_segment']) \\\n","                              .price \\\n","                              .sum() \\\n","                              .unstack(level=1, fill_value=0)\n","\n","monthly_revenue = monthly_revenue[columns]\n","monthly_revenue"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["monthly_revenue.tail(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the monthly revenues by segment\n","monthly_revenue.plot.area(figsize=(20,8))\n","\n","plt.title('Monthly Revenues by Segments', fontsize=14)\n","plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5));"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Total revenues across 29 segments came in at 664,858 in the first eight months of 2018.\n","The biggest segment was 'watches', which generated 17.4% of total revenues (115,901)."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create watches segment dataframe\n","watches = df[df.business_segment == 'watches']\n","watches.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create monthly revenues by product category\n","columns = watches.groupby('product_category_name_english') \\\n","              .price \\\n","              .sum() \\\n","              .sort_values(ascending=False) \\\n","              .index\n","\n","monthly_revenue_category = watches.groupby(['order_purchase_timestamp(y-m)', 'product_category_name_english']) \\\n","                                  .price \\\n","                                  .sum() \\\n","                                  .unstack(level=1, fill_value=0)\n","\n","monthly_revenue_category = monthly_revenue_category[columns]\n","monthly_revenue_category"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the monthly revenues by category\n","monthly_revenue_category.plot.area(figsize=(12,6))\n","plt.title('Monthly Revenues by Product Category of Watches', fontsize=14);"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create 'seller - product category' table\n","cols = watches.groupby('product_category_name_english') \\\n","              .price \\\n","              .sum() \\\n","              .sort_values(ascending=False) \\\n","              .index\n","\n","watches_seller_revenue = watches.groupby(['seller_id', 'product_category_name_english']) \\\n","                                .price \\\n","                                .sum() \\\n","                                .unstack(level=1, fill_value=0)\n","\n","watches_seller_revenue = watches_seller_revenue[cols]\n","watches_seller_revenue['total'] = watches_seller_revenue.sum(axis=1)\n","\n","watches_seller_revenue"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["'watches_gifts' category generated 79.7% of total revenue of segment.\n","'watches_gifts' revenue soared in March and reached its peak in May. This category seems a seasonal item.\n","Except 'watches_gifts', product categories are irrelevant to watches segment.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create 'category - seller' table\n","index = watches.groupby('product_category_name_english') \\\n","               .price \\\n","               .sum() \\\n","               .sort_values() \\\n","               .index\n","\n","seller_category_revenue = watches.groupby(['seller_id', 'product_category_name_english']) \\\n","                                 .price \\\n","                                 .sum() \\\n","                                 .unstack(level=0, fill_value=0) \\\n","                                 \n","seller_category_revenue = seller_category_revenue.reindex(index)\n","seller_category_revenue"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the above table\n","seller_category_revenue.plot.barh(stacked=True, figsize=(12,6))\n","\n","plt.title('Watches Revenue by Seller', fontsize=14)\n","plt.legend(loc='lower right');"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Though 'watches' segment is the largest part of revenue, it has only two sellers.\n","Furthermore, the leading seller generated 97.0% of segment revenue."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[">****Predict future revenue****"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","orders = pd.read_csv('../input/brazilian-ecommerce/olist_orders_dataset.csv')\n","order_item = pd.read_csv('../input/brazilian-ecommerce/olist_order_items_dataset.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["orders = orders[['order_id', 'order_purchase_timestamp']]\n","order_item = order_item[['order_id', 'price']]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["orders_items = pd.merge(orders, order_item, on='order_id')\n","orders_items.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_final = orders_items[['order_purchase_timestamp', 'price']]\n","\n","df_final['order_purchase_timestamp'] = pd.to_datetime(df_final['order_purchase_timestamp'])\n","df_final['order_purchase_timestamp'] = df_final['order_purchase_timestamp'].dt.date\n","df_final=df_final[(df_final['order_purchase_timestamp'] > dt.strptime('2017-01-01', '%Y-%m-%d').date()) &  (df_final['order_purchase_timestamp'] < dt.strptime('2018-09-30', '%Y-%m-%d').date())]\n","\n","df_final.columns = ['order_purchase_timestamp', 'valor']\n","df_final = df_final.sort_values('order_purchase_timestamp')\n","df_final.head(100)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_final = df_final[['order_purchase_timestamp', 'valor']]\n","\n","df_final = df_final.groupby(['order_purchase_timestamp']).sum()\n","df_groupby_copy = df_final\n","\n","df_groupby_copy['data'] = df_final.index.values\n","df_groupby_copy_ARIMA = df_groupby_copy\n","df_groupby_copy.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_groupby_copy = df_groupby_copy[['valor']]\n","df_groupby_copy.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_groupby_copy.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_test_split(df, test_size=0.2):\n","    split_row = len(df) - int(test_size * len(df))\n","    train_data = df.iloc[:split_row]\n","    test_data = df.iloc[split_row:]\n","    return train_data, test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def line_plot(line1, line2, label1=None, label2=None, title='', lw=2):\n","    fig, ax = plt.subplots(1, figsize=(18, 9))\n","    ax.plot(line1, label=label1, linewidth=2)\n","    ax.plot(line2, label=label2, linewidth=2)\n","    ax.set_ylabel('valor', fontsize=14)\n","    ax.set_title(title, fontsize=18)\n","    ax.legend(loc='best', fontsize=18)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train, test = train_test_split(df_groupby_copy, test_size=0.2)\n","\n","line_plot(train.valor, test.valor, 'training', 'test', 'Datasets to compare')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_lookback(dataset, look_back=1):\n","    X, Y = [], []\n","    for i in range(len(dataset) - look_back):\n","        a = dataset[i:(i + look_back), 0]\n","        X.append(a)\n","        Y.append(dataset[i + look_back, 0])\n","    return np.array(X), np.array(Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_set = train.values\n","training_set = np.array(training_set).reshape((-1,1))\n","training_set = np.reshape(training_set, (len(training_set), 1))\n","\n","test_set = test.values\n","test_set = np.array(test_set).reshape((-1,1))\n","test_set = np.reshape(test_set, (len(test_set), 1))\n","\n","#scale datasets\n","scaler = MinMaxScaler()\n","training_set = scaler.fit_transform(training_set)\n","test_set = scaler.transform(test_set)\n","\n","# create datasets which are suitable for time series forecasting\n","look_back = 1\n","X_train, Y_train = create_lookback(training_set, look_back)\n","X_test, Y_test = create_lookback(test_set, look_back)\n","\n"," # reshape datasets so that they will be ok for the requirements of the LSTM model in Keras\n","X_train = np.reshape(X_train, (len(X_train), 1, X_train.shape[1]))\n","X_test = np.reshape(X_test, (len(X_test), 1, X_test.shape[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(LSTM(256, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n","model.add(LSTM(256))\n","model.add(Dense(1))\n","\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","\n","model.summary()\n","\n","history = model.fit(X_train, Y_train, epochs=50, batch_size=16, shuffle=False,\n","                    validation_data=(X_test, Y_test), verbose=1,\n","                    callbacks = [EarlyStopping(monitor='val_loss', min_delta=5e-5, patience=20, verbose=1)])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> ****Predictions****"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["prediction = model.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["prediction_inverse = scaler.inverse_transform(prediction.reshape(-1, 1))\n","Y_test_inverse = scaler.inverse_transform(Y_test.reshape(-1, 1))\n","\n","prediction2_inverse = np.array(prediction_inverse[:,0][1:])\n","Y_test2_inverse = np.array(Y_test_inverse[:,0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y_test2_inverse_without_last = Y_test2_inverse[:-1]\n","RMSE = sqrt(mean_squared_error(Y_test2_inverse_without_last, prediction2_inverse))\n","print('Test RMSE: %.3f' % RMSE)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import plotly.graph_objs as go\n","import plotly.offline as py\n","py.init_notebook_mode(connected=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Test_Dates = test.index\n","\n","trace1 = go.Scatter(x=Test_Dates, y=Y_test2_inverse, name= 'Actual Price',\n","                   line = dict(color = ('rgb(66, 244, 155)'),width = 2))\n","\n","trace2 = go.Scatter(x=Test_Dates, y=prediction2_inverse, name= 'Predicted Price',\n","                   line = dict(color = ('rgb(244, 146, 65)'),width = 2))\n","data = [trace1, trace2]\n","layout = dict(title = 'With purchase date information to predict future sales',\n","             xaxis = dict(title = 'Date'), yaxis = dict(title = 'purchase value'))\n","fig = dict(data=data, layout=layout)\n","py.iplot(fig, filename='results_demonstrating1')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["****ARIMA Prediction****\n","****"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_groupby_copy.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y = df_groupby_copy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y.plot(figsize=(15, 6))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import statsmodels.api as sm\n","import matplotlib.pyplot as plt\n","import itertools\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mod = sm.tsa.statespace.SARIMAX(y,\n","                                order=(1, 1, 1),\n","                                seasonal_order=(1, 1, 1, 12),\n","                                enforce_stationarity=False,\n","                                enforce_invertibility=False)\n","\n","results = mod.fit()\n","\n","print(results.summary().tables[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pred = results.get_prediction(start=0, dynamic=False)\n","pred_ci = pred.conf_int()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ax = y[493:].plot(label='observed', figsize=(18, 9))\n","pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)\n","\n","ax.fill_between(pred_ci.index,\n","                pred_ci.iloc[:, 0],\n","                pred_ci.iloc[:, 1], color='white', alpha=.2)\n","\n","ax.set_xlabel('Date')\n","ax.set_ylabel('Value')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Conclusion:\n","    \n","  We have a clear picture that:\n","    - From all customers only 3% are recurring and remaining 97% are just below 1 year purchasers.\n","    - Total revenues across 29 segments came in at 664,858 in the first eight months of 2018. The biggest segment was 'watches', which generated 17.4% of total revenues (115,901).\n","    - The best categories are watches and audio\n","    - Though 'watches' segment is the largest part of revenue, it has only two sellers. Furthermore, the leading seller generated 97.0% of segment revenue. "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}
